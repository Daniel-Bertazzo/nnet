{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Penna Chaves Bertazzo - 10349561\n",
    "<br>\n",
    "O *dataset* foi dividido usando o método *holdout*, onde o conjunto de treino possui 75% do tamanho do original, e o conjunto de validação contém 25% dos dados.\n",
    "<br>\n",
    "A medida utilizada para avaliação dos classificadores foi a acurácia, visto que os *datasets* utilizados possuem classes bem distribuídas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "### - Classificador binário\n",
    "No caso de uma tarefa de classificação binária (apenas duas classes, positivo e negativo por exemplo), a matriz de confusão é simples: uma tabela 2x2 onde as colunas representam as classes preditas pelo classificador, e as linhas as classes verdadeiras. Por exemplo, tome a matriz de confusão a seguir:\n",
    "\n",
    "$$ \\begin{bmatrix}          & Positivo & Negativo  \\\\\n",
    "                   Positivo & 45       & 4         \\\\\n",
    "                   Negativo & 3        & 53         \\end{bmatrix} $$\n",
    "\n",
    "Em relação à classe positiva (primeira coluna), vemos que um certo algoritmo classificou corretamente 45 instâncias como positivas e 3 erroneamente (foram classificadas como positivas, porém são negativas -> **falsos positivos**). Já em relação à classe negativa (segunda coluna), vemos que ele classificou corretamente 53 instâncias como negativas e 4 erroneamente (foram classificadas como negativas, porém são positivas -> **falsos negativos**).\n",
    "Nesse contexto, pode-se estruturar a matriz da seguinte forma:\n",
    "\n",
    "$$ \\begin{bmatrix}          & Positivo & Negativo  \\\\\n",
    "                   Positivo & TP       & FN        \\\\\n",
    "                   Negativo & FP       & TN        \\end{bmatrix} $$\n",
    "\n",
    "Onde:<br>\n",
    "TP = *true positive* (classificados como positivo e são de fato positivos);<br>\n",
    "TN = *true negative* (classificados como negativo e são de fato negativos);<br>\n",
    "FP = *false positive* (classificados como positivos, porém são negativos);<br>\n",
    "FN = *false negative* (classificados como negativos, porém são positivos).\n",
    "\n",
    "### - Classificador multiclasse\n",
    "No caso de um classificador multiclasse, teremos uma matriz de confusão maior do que 2x2. Na verdade, teremos uma matriz nxn, onde n = número de classes. Nesse caso, os rótulos apresentados acima serão um pouco mais complexos. Dada uma matriz de confusão $C_{ij}$:\n",
    "\n",
    "$$ \\begin{bmatrix} C_{11} & \\cdots & C_{1n} \\\\\n",
    "                   \\vdots & \\ddots & \\vdots \\\\\n",
    "                   C_{n1} & \\cdots & C_{nn} \\end{bmatrix} $$\n",
    "\n",
    "Não é mais possível calcular os rótulos de forma geral. É preciso calcular para cada classe:\n",
    "<br><br>\n",
    "TP = $C_{ij}$, onde $i=j$. Isso representa a diagonal principal, ou seja, todas as instâncias cuja classe predita $j$ é igual à classe verdadeira $i$;\n",
    "<br><br>\n",
    "TN = $ \\Big(\\sum_{i \\neq c,j \\neq c} C_{ij}\\Big) $, onde $c$ é a classe da qual queremos extrair tal informação. Em outras palavras, isso representa a soma de todos as instâncias que não foram classificadas como $c$ e, de fato, não são da classe $c$.\n",
    "<br><br>\n",
    "FP = $ \\Big(\\sum_{i \\neq c} C_{ic}\\Big) $, onde $c$ é a classe da qual queremos extrair tal informação. Essa expressão representa a soma da coluna inteira da classe $c$, com exceção da instância onde $c=i$, ou seja, aquela que foi corretamente predita. Com isso, estamos somando todas as instâncias classificadas como sendo da classe $c$, porém que não são, de fato, de tal *label*.\n",
    "<br><br>\n",
    "FN = $ \\Big(\\sum_{j \\neq c} C_{cj}\\Big) $, onde $c$ é a classe da qual queremos extrair tal informação. Essa expressão representa a soma da linha inteira da classe $c$, com exceção da instância onde $c=j$, ou seja, aquela que foi corretamente predita. Com isso, estamos somando todas as instâncias pertencentes à classe $c$, porém que foram classificadas erroneamente com outro *label*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_3Cluster_4features.csv')\n",
    "\n",
    "# Divide o dataset em conjunto de treino e conjunto de validacao\n",
    "train_set, val_set = train_test_split(df, test_size=0.25)\n",
    "\n",
    "# Divide o conjunto de treino em features e labels\n",
    "X_train = train_set.iloc[:, :-1]\n",
    "y_train = train_set.iloc[:, -1]\n",
    "# Divide o conjunto de validacao em features e labels\n",
    "X_val = val_set.iloc[:, :-1]\n",
    "y_val = val_set.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o primeiro modelo\n",
    "classifier1 = MLPClassifier(hidden_layer_sizes=(10, 7), max_iter=1000, activation='relu',\n",
    "                           learning_rate_init=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o segundo modelo\n",
    "classifier2 = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000, activation='logistic',\n",
    "                           learning_rate_init=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o primeiro modelo\n",
    "classifier1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o segundo modelo\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a predicao usando o conjunto de treino => para calcular o erro empirico da generalizacao\n",
    "y_emp1 = classifier1.predict(X_train)\n",
    "y_emp2 = classifier2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a predicao usando o conjunto de testes => para poder calcular a metrica de avaliacao do modelo\n",
    "y_pred1 = classifier1.predict(X_val)\n",
    "y_pred2 = classifier2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera as matrizes de confusao dos resultados\n",
    "cm_emp1  = confusion_matrix(y_train, y_emp1)\n",
    "cm_emp2  = confusion_matrix(y_train, y_emp2)\n",
    "cm_pred1 = confusion_matrix(y_val, y_pred1)\n",
    "cm_pred2 = confusion_matrix(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    '''\n",
    "    Retorna a acuracia de um modelo, dada sua matriz de confusao.\n",
    "    O metodo consiste em somar os elementos da diagonal principal (corretamente preditos)\n",
    "    e dividir pela soma de todos os elementos da matriz (numero total de predicoes)\n",
    "    Input:\n",
    "        cm: matriz de confusao\n",
    "    Return:\n",
    "        Acuracia do modelo\n",
    "    '''\n",
    "    return cm.trace() / cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula as acuracias empiricas (erro no conjunto de treino)\n",
    "acc_emp1 = accuracy(cm_emp1)\n",
    "acc_emp2 = accuracy(cm_emp2)\n",
    "\n",
    "# Calcula as acuracias estimadas (erro no conjunto de validacao)\n",
    "acc_est1 = accuracy(cm_pred1)\n",
    "acc_est2 = accuracy(cm_pred2)\n",
    "\n",
    "# Calcula os riscos\n",
    "Remp1 = 1 - acc_emp1\n",
    "Remp2 = 1 - acc_emp2\n",
    "\n",
    "Rest1 = 1 - acc_est1\n",
    "Rest2 = 1 - acc_est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Risco empirico do modelo 1: ', 1 - Remp1)\n",
    "print('Risco empirico do modelo 2: ', 1 - Remp2)\n",
    "print()\n",
    "print('Risco estimado do modelo 1: ', 1 - Rest1)\n",
    "print('Risco estimado do modelo 2: ', 1 - Rest2)\n",
    "\n",
    "print('\\nDe acordo com os valores dos riscos (erros), o modelo que melhor generalizou foi: ')\n",
    "\n",
    "if Rest1 < Rest2:\n",
    "    print('o primeiro modelo!')\n",
    "elif Rest2 < Rest1:\n",
    "    print('o segundo modelo!')\n",
    "else:\n",
    "    print('ambos!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda1396f5dd0753419f96fe7856bd455978"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
