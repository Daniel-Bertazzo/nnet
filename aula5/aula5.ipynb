{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Daniel Penna Chaves Bertazzo - 10349561\n",
    "<br>\n",
    "SCC0270 - Redes Neurais e Aprendizado Profundo\n",
    "<br>\n",
    "Aula 5 - prática**\n",
    "<br><br>\n",
    "Para o exercício 2, o *dataset* foi dividido usando o método *holdout*, onde o conjunto de treino possui 75% do tamanho do original, e o conjunto de validação contém 25% dos dados.\n",
    "<br>\n",
    "Já para o exercício 3, o método de divisão foi o mesmo, porém com uma proporção 70/30.\n",
    "<br>\n",
    "A medida utilizada para avaliação dos classificadores para os exercícios 2 e 3 foi a acurácia, visto que os *datasets* utilizados possuem classes bem distribuídas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "### - Classificador binário\n",
    "No caso de uma tarefa de classificação binária (apenas duas classes, positivo e negativo por exemplo), a matriz de confusão é simples: uma tabela 2x2 onde as colunas representam as classes preditas pelo classificador, e as linhas as classes verdadeiras. Por exemplo, tome a matriz de confusão a seguir:\n",
    "\n",
    "$$ \\begin{bmatrix}          & Positivo & Negativo  \\\\\n",
    "                   Positivo & 45       & 4         \\\\\n",
    "                   Negativo & 3        & 53         \\end{bmatrix} $$\n",
    "\n",
    "Em relação à classe positiva (primeira coluna), vemos que um certo algoritmo classificou corretamente 45 instâncias como positivas e 3 erroneamente (foram classificadas como positivas, porém são negativas -> **falsos positivos**). Já em relação à classe negativa (segunda coluna), vemos que ele classificou corretamente 53 instâncias como negativas e 4 erroneamente (foram classificadas como negativas, porém são positivas -> **falsos negativos**).\n",
    "Nesse contexto, pode-se estruturar a matriz da seguinte forma:\n",
    "\n",
    "$$ \\begin{bmatrix}          & Positivo & Negativo  \\\\\n",
    "                   Positivo & TP       & FN        \\\\\n",
    "                   Negativo & FP       & TN        \\end{bmatrix} $$\n",
    "\n",
    "Onde:<br>\n",
    "TP = *true positive* (classificados como positivo e são de fato positivos);<br>\n",
    "TN = *true negative* (classificados como negativo e são de fato negativos);<br>\n",
    "FP = *false positive* (classificados como positivos, porém são negativos);<br>\n",
    "FN = *false negative* (classificados como negativos, porém são positivos).\n",
    "\n",
    "### - Classificador multiclasse\n",
    "No caso de um classificador multiclasse, teremos uma matriz de confusão maior do que 2x2. Na verdade, teremos uma matriz nxn, onde n = número de classes. Nesse caso, os rótulos apresentados acima serão um pouco mais complexos. Dada uma matriz de confusão $C_{ij}$:\n",
    "\n",
    "$$ \\begin{bmatrix} C_{11} & \\cdots & C_{1n} \\\\\n",
    "                   \\vdots & \\ddots & \\vdots \\\\\n",
    "                   C_{n1} & \\cdots & C_{nn} \\end{bmatrix} $$\n",
    "\n",
    "Não é mais possível calcular os rótulos de forma geral. É preciso calcular para cada classe:\n",
    "<br><br>\n",
    "TP = $C_{ij}$, onde $i=j$. Isso representa a diagonal principal, ou seja, todas as instâncias cuja classe predita $j$ é igual à classe verdadeira $i$;\n",
    "<br><br>\n",
    "TN = $ \\Big(\\sum_{i \\neq c,j \\neq c} C_{ij}\\Big) $, onde $c$ é a classe da qual queremos extrair tal informação. Em outras palavras, isso representa a soma de todos as instâncias que não foram classificadas como $c$ e, de fato, não são da classe $c$.\n",
    "<br><br>\n",
    "FP = $ \\Big(\\sum_{i \\neq c} C_{ic}\\Big) $, onde $c$ é a classe da qual queremos extrair tal informação. Essa expressão representa a soma da coluna inteira da classe $c$, com exceção da instância onde $c=i$, ou seja, aquela que foi corretamente predita. Com isso, estamos somando todas as instâncias classificadas como sendo da classe $c$, porém que não são, de fato, de tal *label*.\n",
    "<br><br>\n",
    "FN = $ \\Big(\\sum_{j \\neq c} C_{cj}\\Big) $, onde $c$ é a classe da qual queremos extrair tal informação. Essa expressão representa a soma da linha inteira da classe $c$, com exceção da instância onde $c=j$, ou seja, aquela que foi corretamente predita. Com isso, estamos somando todas as instâncias pertencentes à classe $c$, porém que foram classificadas erroneamente com outro *label*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_3Cluster_4features.csv')\n",
    "\n",
    "# Divide o dataset em conjunto de treino e conjunto de validacao\n",
    "train_set, test_set = train_test_split(df, test_size=0.25)\n",
    "\n",
    "# Divide o conjunto de treino em features e labels\n",
    "X_train = train_set.iloc[:, :-1]\n",
    "y_train = train_set.iloc[:, -1]\n",
    "# Divide o conjunto de validacao em features e labels\n",
    "X_test = test_set.iloc[:, :-1]\n",
    "y_test = test_set.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o primeiro modelo\n",
    "classifier1 = MLPClassifier(hidden_layer_sizes=(3, 3), max_iter=1000, activation='relu',\n",
    "                           learning_rate_init=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o segundo modelo\n",
    "classifier2 = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000, activation='logistic',\n",
    "                           learning_rate_init=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(3, 3), learning_rate='constant',\n",
       "              learning_rate_init=0.1, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina o primeiro modelo\n",
    "classifier1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "              learning_rate_init=0.1, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina o segundo modelo\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a predicao usando o conjunto de treino => para calcular o erro empirico da generalizacao\n",
    "y_emp1 = classifier1.predict(X_train)\n",
    "y_emp2 = classifier2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a predicao usando o conjunto de testes => para poder calcular a metrica de avaliacao do modelo\n",
    "y_pred1 = classifier1.predict(X_test)\n",
    "y_pred2 = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera as matrizes de confusao dos resultados\n",
    "cm_emp1  = confusion_matrix(y_train, y_emp1)\n",
    "cm_emp2  = confusion_matrix(y_train, y_emp2)\n",
    "cm_pred1 = confusion_matrix(y_test, y_pred1)\n",
    "cm_pred2 = confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    '''\n",
    "    Retorna a acuracia de um modelo, dada sua matriz de confusao.\n",
    "    O metodo consiste em somar os elementos da diagonal principal (corretamente preditos)\n",
    "    e dividir pela soma de todos os elementos da matriz (numero total de predicoes)\n",
    "    Input:\n",
    "        cm: matriz de confusao\n",
    "    Return:\n",
    "        Acuracia do modelo\n",
    "    '''\n",
    "    return cm.trace() / cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula as acuracias empiricas (erro no conjunto de treino)\n",
    "acc_emp1 = accuracy(cm_emp1)\n",
    "acc_emp2 = accuracy(cm_emp2)\n",
    "\n",
    "# Calcula as acuracias estimadas (erro no conjunto de validacao)\n",
    "acc_est1 = accuracy(cm_pred1)\n",
    "acc_est2 = accuracy(cm_pred2)\n",
    "\n",
    "# Calcula os riscos\n",
    "Remp1 = 1 - acc_emp1\n",
    "Remp2 = 1 - acc_emp2\n",
    "\n",
    "Rest1 = 1 - acc_est1\n",
    "Rest2 = 1 - acc_est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risco empirico do modelo 1:  0.013333333333333308\n",
      "Risco empirico do modelo 2:  0.004444444444444473\n",
      "\n",
      "Risco estimado do modelo 1:  0.013333333333333308\n",
      "Risco estimado do modelo 2:  0.0\n",
      "Acuracia do modelo 1:  0.9866666666666667\n",
      "Acuracia do modelo 2:  1.0\n",
      "\n",
      "De acordo com os valores dos riscos (erros), o modelo que melhor generalizou foi: \n",
      "o segundo modelo!\n"
     ]
    }
   ],
   "source": [
    "print('Risco empirico do modelo 1: ', Remp1)\n",
    "print('Risco empirico do modelo 2: ', Remp2)\n",
    "print()\n",
    "print('Risco estimado do modelo 1: ', Rest1)\n",
    "print('Risco estimado do modelo 2: ', Rest2)\n",
    "\n",
    "print('Acuracia do modelo 1: ', acc_est1)\n",
    "print('Acuracia do modelo 2: ', acc_est2)\n",
    "\n",
    "print('\\nDe acordo com os valores dos riscos (erros), o modelo que melhor generalizou foi: ')\n",
    "\n",
    "if Rest1 < Rest2:\n",
    "    print('o primeiro modelo!')\n",
    "elif Rest2 < Rest1:\n",
    "    print('o segundo modelo!')\n",
    "else:\n",
    "    print('ambos!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que, para o *dataset* `Dataset_3Cluster_4features.csv`, ambos os modelos são capazes de generalizar muito bem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset Iris\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o primeiro modelo\n",
    "classifier1 = MLPClassifier(hidden_layer_sizes=(3, 3), max_iter=1000, activation='relu',\n",
    "                           learning_rate_init=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o segundo modelo\n",
    "classifier2 = MLPClassifier(hidden_layer_sizes=(5, 5), max_iter=1000, activation='logistic',\n",
    "                           learning_rate_init=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(3, 3), learning_rate='constant',\n",
       "              learning_rate_init=0.1, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina o primeiro modelo\n",
    "classifier1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "              learning_rate_init=0.1, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina o segundo modelo\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a predicao usando o conjunto de treino => para calcular o erro empirico da generalizacao\n",
    "y_emp1 = classifier1.predict(X_train)\n",
    "y_emp2 = classifier2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a predicao usando o conjunto de testes => para poder calcular a metrica de avaliacao do modelo\n",
    "y_pred1 = classifier1.predict(X_test)\n",
    "y_pred2 = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera as matrizes de confusao dos resultados\n",
    "cm_emp1  = confusion_matrix(y_train, y_emp1)\n",
    "cm_emp2  = confusion_matrix(y_train, y_emp2)\n",
    "cm_pred1 = confusion_matrix(y_test, y_pred1)\n",
    "cm_pred2 = confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    '''\n",
    "    Retorna a acuracia de um modelo, dada sua matriz de confusao.\n",
    "    O metodo consiste em somar os elementos da diagonal principal (corretamente preditos)\n",
    "    e dividir pela soma de todos os elementos da matriz (numero total de predicoes)\n",
    "    Input:\n",
    "        cm: matriz de confusao\n",
    "    Return:\n",
    "        Acuracia do modelo\n",
    "    '''\n",
    "    return cm.trace() / cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula as acuracias empiricas (erro no conjunto de treino)\n",
    "acc_emp1 = accuracy(cm_emp1)\n",
    "acc_emp2 = accuracy(cm_emp2)\n",
    "\n",
    "# Calcula as acuracias estimadas (erro no conjunto de validacao)\n",
    "acc_est1 = accuracy(cm_pred1)\n",
    "acc_est2 = accuracy(cm_pred2)\n",
    "\n",
    "# Calcula os riscos\n",
    "Remp1 = 1 - acc_emp1\n",
    "Remp2 = 1 - acc_emp2\n",
    "\n",
    "Rest1 = 1 - acc_est1\n",
    "Rest2 = 1 - acc_est2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risco empirico do modelo 1:  0.2952380952380952\n",
      "Risco empirico do modelo 2:  0.01904761904761909\n",
      "\n",
      "Risco estimado do modelo 1:  0.4222222222222223\n",
      "Risco estimado do modelo 2:  0.0\n",
      "Acuracia do modelo 1:  0.5777777777777777\n",
      "Acuracia do modelo 2:  1.0\n",
      "\n",
      "De acordo com os valores dos riscos (erros), o modelo que melhor generalizou foi: \n",
      "o segundo modelo!\n"
     ]
    }
   ],
   "source": [
    "print('Risco empirico do modelo 1: ', Remp1)\n",
    "print('Risco empirico do modelo 2: ', Remp2)\n",
    "print()\n",
    "print('Risco estimado do modelo 1: ', Rest1)\n",
    "print('Risco estimado do modelo 2: ', Rest2)\n",
    "\n",
    "print('Acuracia do modelo 1: ', acc_est1)\n",
    "print('Acuracia do modelo 2: ', acc_est2)\n",
    "\n",
    "print('\\nDe acordo com os valores dos riscos (erros), o modelo que melhor generalizou foi: ')\n",
    "\n",
    "if Rest1 < Rest2:\n",
    "    print('o primeiro modelo!')\n",
    "elif Rest2 < Rest1:\n",
    "    print('o segundo modelo!')\n",
    "else:\n",
    "    print('ambos!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que para o *dataset* `Iris`, o primeiro modelo não foi capaz de generalizar, ficando com uma acurácia perto de 50%, o que indica uma classificação aleatória. Já o segundo modelo resultou em uma acurácia de 100%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda1396f5dd0753419f96fe7856bd455978"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
