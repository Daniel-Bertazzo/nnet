{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC0270 - Redes Neurais e Aprendizado Profundo\n",
    "### Aula 7 - Prática (Redes neurais convolutivas)\n",
    "**Daniel Penna Chaves Bertazzo - 10349561**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "A função de ativação *softmax* é dada pela fórmula\n",
    "<br><br>\n",
    "$$ S(y_i) = \\frac{e^{y_i}} {\\sum_{j=1}^{K} e^{y_j}} $$\n",
    "<br>\n",
    "onde $K$ é o número de classes presentes no *dataset*. Tal função de ativação possui como entrada um vetor de $K$ elementos ($\\in \\mathbb{R}$) e o normaliza para uma distribuição de probabilidade (outro vetor com $K$ elementos, onde cada elemento representa uma probabilidade proporcional aos exponenciais dos valores de entrada). No contexto de redes neurais, é normalmente utilizada na camada de saída, pois pega como entrada os valores gerados pelas ativações dos neurônios da penúltima camada e os transforma em um vetor onde cada $S(y_i)$ representa a probabilidade da classe $i$ ser a predição correta para aquela instância do *dataset*. Por exemplo:\n",
    "<br><br>\n",
    "Suponha que possuímos um *dataset* com 3 classes diferentes e uma rede neural treinada para prever corretamente à qual classe uma dada instância pertence. Ao fornecer à rede tal exemplo, suponha que ela retorne como resultado o vetor:\n",
    "<br><br>\n",
    "$$ \\begin{bmatrix} {0.02 \\\\\n",
    "                    0.98 \\\\\n",
    "                    0.00} \\end{bmatrix} $$\n",
    "<br>\n",
    "onde cada linha representa uma classe $y$. Nesse caso, temos que\n",
    "* $P(y=1) = 2\\%$\n",
    "* $P(y=2) = 98\\%$\n",
    "* $P(y=3) = 0\\%$\n",
    "<br>\n",
    "Logo, de acordo com o modelo, a instância em questão tem 98% de probabilidade de ser da classe 2, sendo classificada como tal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "A função de ativação ReLU é dada pela fórmula\n",
    "<br>\n",
    "$$ y = \\max(0, x) $$\n",
    "<br>\n",
    "e possui comportamento constante em zero para todos os valores menores que zero e linear crescente para qualquer valor maior que zero. Essa função é a mais comumente utilizada em redes neurais convolutivas pois, além de ser rápida de calcular, ela não satura (não converge para um valor fixo de acordo com o crescimento de $y$, diferente da ativação sigmóide) e é ativada de forma esparsa, ou seja, a maioria das entradas $y$ serão transformadas em zero (não ativam o neurônio), simulando de forma mais realista a forma como o cérebro biológico, principal insipiração para redes neurais, funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o formato dos dados para serem compativeis com o modelo de rede neural\n",
    "# X_train: formato antigo = (60000, 28, 28) --> formato novo: (60000, 28, 28, 1)\n",
    "# X_test: formato antigo = (10000, 28, 28) --> formato novo: (10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o formato dos targets para serem compativeis com o modelo de rede neural\n",
    "# Faz one-hot encoding\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1\n",
    "* **Primeira camada:** convolução com 32 filtros 3x3 e ativação relu + max_pooling 2x2\n",
    "\n",
    "* **Segunda camada:** convolução com 64 filtros 3x3 e ativação relu + max_pooling 2x2\n",
    "\n",
    "* **Última camada:** *fully connected* com 10 neurônios (número de clases) e ativação softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Primeira camada de convolucao e max-pooling\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Segunda camdada de convolicao e max-pooling\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# \"Achata\" os dados para um vetor unidimensional\n",
    "model.add(Flatten())\n",
    "\n",
    "# Ultima camada: fully connected com 10 neuronios (1 para cada classe) e\n",
    "# ativacao softmax para obter as probabilidades\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "# adam optimizer: otimizador que ajusta o learning rate\n",
    "# categorical_crossentropy: usada para problemas de classificacoes com multiplas classes\n",
    "# accuracy: metrica usada para ver a eficacia do modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 29s 486us/sample - loss: 0.0740 - accuracy: 0.9776 - val_loss: 0.0703 - val_accuracy: 0.9774\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 34s 567us/sample - loss: 0.0576 - accuracy: 0.9833 - val_loss: 0.0724 - val_accuracy: 0.9758\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 33s 544us/sample - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0549 - val_accuracy: 0.9840\n",
      "CPU times: user 3min 43s, sys: 2min 12s, total: 5min 55s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f904d2959d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Treina o modelo\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0338 - accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss =  0.03379081192867234 \n",
      "accuracy =  0.98968333\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss = \", loss, \"\\naccuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
