{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC0270 - Redes Neurais e Aprendizado Profundo\n",
    "### Aula 7 - Prática (Redes neurais convolutivas)\n",
    "**Daniel Penna Chaves Bertazzo - 10349561**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 1\n",
    "A função de ativação *softmax* é dada pela fórmula\n",
    "<br><br>\n",
    "$$ S(y_i) = \\frac{e^{y_i}} {\\sum_{j=1}^{K} e^{y_j}} $$\n",
    "<br>\n",
    "onde $K$ é o número de classes presentes no *dataset*. Tal função de ativação possui como entrada um vetor de $K$ elementos ($\\in \\mathbb{R}$) e o normaliza para uma distribuição de probabilidade (outro vetor com $K$ elementos, onde cada elemento representa uma probabilidade proporcional aos exponenciais dos valores de entrada). No contexto de redes neurais, é normalmente utilizada na camada de saída, pois pega como entrada os valores gerados pelas ativações dos neurônios da penúltima camada e os transforma em um vetor onde cada $S(y_i)$ representa a probabilidade da classe $i$ ser a predição correta para aquela instância do *dataset*. Por exemplo:\n",
    "<br><br>\n",
    "Suponha que possuímos um *dataset* com 3 classes diferentes e uma rede neural treinada para prever corretamente à qual classe uma dada instância pertence. Ao fornecer à rede tal exemplo, suponha que ela retorne como resultado o vetor:\n",
    "<br><br>\n",
    "$$ \\begin{bmatrix} {0.02 \\\\\n",
    "                    0.98 \\\\\n",
    "                    0.00} \\end{bmatrix} $$\n",
    "<br>\n",
    "onde cada linha representa uma classe $y$. Nesse caso, temos que\n",
    "* $P(y=1) = 2\\%$\n",
    "* $P(y=2) = 98\\%$\n",
    "* $P(y=3) = 0\\%$\n",
    "<br>\n",
    "Logo, de acordo com o modelo, a instância em questão tem 98% de probabilidade de ser da classe 2, sendo classificada como tal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2\n",
    "A função de ativação ReLU é dada pela fórmula\n",
    "<br>\n",
    "$$ y = \\max(0, x) $$\n",
    "<br>\n",
    "e possui comportamento constante em zero para todos os valores menores que zero e linear crescente para qualquer valor maior que zero. Essa função é a mais comumente utilizada em redes neurais convolutivas pois, além de ser rápida de calcular, ela não satura (não converge para um valor fixo de acordo com o crescimento de $y$, diferente da ativação sigmóide) e é ativada de forma esparsa, ou seja, a maioria das entradas $y$ serão transformadas em zero (não ativam o neurônio), simulando de forma mais realista a forma como o cérebro biológico, principal insipiração para redes neurais, funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o formato dos dados para serem compativeis com o modelo de rede neural\n",
    "# X_train: formato antigo = (60000, 28, 28) --> formato novo: (60000, 28, 28, 1)\n",
    "# X_test: formato antigo = (10000, 28, 28) --> formato novo: (10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o formato dos targets para serem compativeis com o modelo de rede neural\n",
    "# Faz one-hot encoding\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1\n",
    "* **Primeira camada:** convolução com 32 filtros 3x3 e ativação relu + max_pooling 2x2\n",
    "\n",
    "* **Segunda camada:** convolução com 64 filtros 3x3 e ativação relu + max_pooling 2x2\n",
    "\n",
    "* **Última camada:** *fully connected* com 10 neurônios (número de classes) e ativação softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# Primeira camada de convolucao e max-pooling\n",
    "model1.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Segunda camdada de convolicao e max-pooling\n",
    "model1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# \"Achata\" os dados para um vetor unidimensional\n",
    "model1.add(Flatten())\n",
    "\n",
    "# Ultima camada: fully connected com 10 neuronios (1 para cada classe) e\n",
    "# ativacao softmax para obter as probabilidades\n",
    "model1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "# adam optimizer: otimizador que ajusta o learning rate\n",
    "# categorical_crossentropy: usada para problemas de classificacoes com multiplas classes\n",
    "# accuracy: metrica usada para ver a eficacia do modelo\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/3\n",
      "42000/42000 [==============================] - 27s 631us/sample - loss: 0.3396 - accuracy: 0.9399 - val_loss: 0.0959 - val_accuracy: 0.9736\n",
      "Epoch 2/3\n",
      "42000/42000 [==============================] - 33s 793us/sample - loss: 0.0759 - accuracy: 0.9784 - val_loss: 0.0729 - val_accuracy: 0.9794\n",
      "Epoch 3/3\n",
      "42000/42000 [==============================] - 31s 728us/sample - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.0895 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe14c6ca550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina o modelo\n",
    "model1.fit(X_train, y_train, validation_split=0.3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz predicoes com conjunto de teste\n",
    "y_pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia no conjunto de teste =  0.9782\n"
     ]
    }
   ],
   "source": [
    "m1 = tf.keras.metrics.CategoricalAccuracy()\n",
    "m1.update_state(y_test, y_pred1)\n",
    "print(\"Acuracia no conjunto de teste = \", m1.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2\n",
    "* **Primeira camada:** convolução com 64 filtros 3x3 e ativação relu + max_pooling 2x2\n",
    "\n",
    "* **Segunda camada:** convolução com 32 filtros 3x3 e ativação relu + max_pooling 2x2\n",
    "\n",
    "* **Última camada:** *fully connected* com 10 neurônios (número de classes) e ativação softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# Primeira camada de convolucao e max-pooling\n",
    "model2.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Segunda camdada de convolicao e max-pooling\n",
    "model2.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# \"Achata\" os dados para um vetor unidimensional\n",
    "model2.add(Flatten())\n",
    "\n",
    "# Ultima camada: fully connected com 10 neuronios (1 para cada classe) e\n",
    "# ativacao softmax para obter as probabilidades\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 27,114\n",
      "Trainable params: 27,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "# adam optimizer: otimizador que ajusta o learning rate\n",
    "# categorical_crossentropy: usada para problemas de classificacoes com multiplas classes\n",
    "# accuracy: metrica usada para ver a eficacia do modelo\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/3\n",
      "42000/42000 [==============================] - 33s 795us/sample - loss: 0.5202 - accuracy: 0.9117 - val_loss: 0.1310 - val_accuracy: 0.9612\n",
      "Epoch 2/3\n",
      "42000/42000 [==============================] - 36s 852us/sample - loss: 0.1060 - accuracy: 0.9677 - val_loss: 0.0977 - val_accuracy: 0.9691\n",
      "Epoch 3/3\n",
      "42000/42000 [==============================] - 35s 829us/sample - loss: 0.0785 - accuracy: 0.9761 - val_loss: 0.1014 - val_accuracy: 0.9691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe10967a510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina o modelo\n",
    "model2.fit(X_train, y_train, validation_split=0.3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz predicoes com conjunto de teste\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia no conjunto de teste =  0.9733\n"
     ]
    }
   ],
   "source": [
    "m2 = tf.keras.metrics.CategoricalAccuracy()\n",
    "m2.update_state(y_test, y_pred2)\n",
    "print(\"Acuracia no conjunto de teste = \", m2.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados e conclusões\n",
    "<br><br>\n",
    "![Tabela](tabela.png)\n",
    "<br><br>\n",
    "Percebe-se que o modelo *multilayer perceptron* utilizado no trabalho avaliativo possui uma acurácia maior durante a fase de treinamento, porém ambos os modelos convolutivos apresentam resultados melhores na fase de teste, ou seja, eles possuem uma maior capacidade de generalização do aprendizado.\n",
    "<br><br>\n",
    "Portanto, conclui-se que para este *dataset*, que é composto por imagens, um modelo convolutivo mostra-se mais apropriado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
